\documentclass{article}

\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{hyperref}

\begin{document}

\title{Pol Sci 630:  Problem Set 10: Functional Form, Endogeneity, Power}

\author{Prepared by: Anh Le (\href{mailto:anh.le@duke.edu}{anh.le@duke.edu})}

\date{Due Date: Nov 9 (Beginning of Class)}

\maketitle

\section{Functional specification}

There's a famous dataset called the Anscombe quartet. You load it in R like so:

<<>>=
head(anscombe)
@

\subsection{Explore Anscombe}

There are 4 pairs of $x$ and $y$. Run 4 regressions of y on x. Check out the regression result. A bit late for Halloween, but what spooky thing do you notice?

Then plot the data.

\subsection{Ramsey RESET}

Use Ramsey RESET on the 4 models. Which kind of functional misclassification can it catch? Can you think of why?

\section{Endogeneity -- Omitted Variable Bias}

\subsection{Sign the bias -- math}

Given the following data generating process (DGP)

\begin{align}
x_2 &= \delta_0 + \delta_1 x_1 + v \\
y &= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + w
\end{align}

The following equation (lecture 09/26) shows what happens when we regress $y$ on $x_1$, omitting $x_2$. \textbf{Prove this equation}.

$$
y = (\beta_0 + \beta_2 \delta_0) + (\beta_1 + \beta_2 \delta_1) x_1 + (\beta_2 v + w)
$$


\subsection{Sign the bias - simulation}

In the equation you proved above, the estimated coefficient for $x_1$ is $\beta_1 + \beta_2 \delta_1$, different from its true value $\beta_1$. The bias is $\beta_2\delta_1$. The sign of the bias thus depends on $\beta_2$ and $\delta_1$, as discussed in the lecture and reproduced in Table 1.

\begin{table}[]
\centering
\caption{Signing the bias}
\label{my-label}
\begin{tabular}{|l|l|l|}
\hline
               & $\beta_2 > 0$ & $\beta_2 < 0$ \\ \hline
$\delta_1 > 0$ &               &               \\ \hline
$\delta_1 < 0$ &               &               \\ \hline
\end{tabular}
\end{table}

Conduct 4 simulations with appropriate values of $\beta_2$ and $\delta_1$ corresponding to the 4 cells in the table. Show that the sign of the bias is as we learned in class.

\section{Power calculation}

In this exercise we practice power calculation for the simplest experiment setup.

Assume that our binary treatment has an effect size of 2 on the outcome, as follows:

$$
\begin{aligned}
y &= 1 + 2 \times \text{Treatment} + u \\
u &\sim Normal(mean = 1, sd = 10) \\
\end{aligned}
$$

In our experiment, we randomly assigned $n$ experimental units into 2 groups, treated and control, i.e. treatment = 1 and treatment = 0. Calculate the power of our experiment (i.e. the probability that we can reject the null of zero treatment effect) for different values of the sample size $n$.

The end product I want to see is a graph with $n$ on the x-axis and power on the y-axis. How big must your sample size be to get a power of 0.8?

\end{document}
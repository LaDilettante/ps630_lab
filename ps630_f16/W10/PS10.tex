\documentclass{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\title{Pol Sci 630:  Problem Set 10: Functional Form, Endogeneity, Power}

\author{Prepared by: Anh Le (\href{mailto:anh.le@duke.edu}{anh.le@duke.edu})}

\date{Due Date: Nov 9 (Beginning of Class)}

\maketitle

\section{Functional specification}

There's a famous dataset called the Anscombe quartet. You load it in R like so:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{head}\hlstd{(anscombe)}
\end{alltt}
\begin{verbatim}
##   x1 x2 x3 x4   y1   y2    y3   y4
## 1 10 10 10  8 8.04 9.14  7.46 6.58
## 2  8  8  8  8 6.95 8.14  6.77 5.76
## 3 13 13 13  8 7.58 8.74 12.74 7.71
## 4  9  9  9  8 8.81 8.77  7.11 8.84
## 5 11 11 11  8 8.33 9.26  7.81 8.47
## 6 14 14 14  8 9.96 8.10  8.84 7.04
\end{verbatim}
\end{kframe}
\end{knitrout}

\subsection{Explore Anscombe}

There are 4 pairs of $x$ and $y$. Run 4 regressions of y on x. Check out the regression result. A bit late for Halloween, but what spooky thing do you notice?

Then plot the data.

\subsection{Ramsey RESET}

Use Ramsey RESET on the 4 models. Which kind of functional misclassification can it catch? Can you think of why?

\section{Endogeneity -- Omitted Variable Bias}

\subsection{Sign the bias -- math}

Given the following data generating process (DGP)

\begin{align}
x_2 &= \delta_0 + \delta_1 x_1 + v \\
y &= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + w
\end{align}

The following equation (lecture 09/26) shows what happens when we regress $y$ on $x_1$, omitting $x_2$. \textbf{Prove this equation}.

$$
y = (\beta_0 + \beta_2 \delta_0) + (\beta_1 + \beta_2 \delta_1) x_1 + (\beta_2 v + w)
$$


\subsection{Sign the bias - simulation}

In the equation you proved above, the estimated coefficient for $x_1$ is $\beta_1 + \beta_2 \delta_1$, different from its true value $\beta_1$. The bias is $\beta_2\delta_1$. The sign of the bias thus depends on $\beta_2$ and $\delta_1$, as discussed in the lecture and reproduced in Table 1.

\begin{table}[]
\centering
\caption{Signing the bias}
\label{my-label}
\begin{tabular}{|l|l|l|}
\hline
               & $\beta_2 > 0$ & $\beta_2 < 0$ \\ \hline
$\delta_1 > 0$ &               &               \\ \hline
$\delta_1 < 0$ &               &               \\ \hline
\end{tabular}
\end{table}

Conduct 4 simulations with appropriate values of $\beta_2$ and $\delta_1$ corresponding to the 4 cells in the table. Show that the sign of the bias is as we learned in class.

\section{Power calculation}

In this exercise we practice power calculation for the simplest experiment setup.

Assume that our binary treatment has an effect size of 2 on the outcome, as follows:

$$
\begin{aligned}
y &= 1 + 2 \times \text{Treatment} + u \\
u &\sim Normal(mean = 1, sd = 10) \\
\end{aligned}
$$

In our experiment, we randomly assigned $n$ experimental units into 2 groups, treated and control, i.e. treatment = 1 and treatment = 0. Calculate the power of our experiment (i.e. the probability that we can reject the null of zero treatment effect) for different values of the sample size $n$.

The end product I want to see is a graph with $n$ on the x-axis and power on the y-axis. How big must your sample size be to get a power of 0.8?

\end{document}
